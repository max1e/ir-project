{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Information Retrieval"
   ],
   "metadata": {
    "id": "mZz1lygv6Ked",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "## General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "## Data retrieval\n",
    "import os\n",
    "\n",
    "## Data exploration\n",
    "import glob\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "## Pyserini\n",
    "import pyserini\n",
    "from pyserini.index import IndexReader\n",
    "\n",
    "## Models\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ],
   "metadata": {
    "id": "c3ngOuO47SUZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data retrieval"
   ],
   "metadata": {
    "id": "mccGnDk16Pkw",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we download the msmarco passage and index our documents in Lucene."
   ],
   "metadata": {
    "id": "zzTH1oD19X9z",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Download msmarco\n",
    "if not os.path.exists('data/'):\n",
    " # Download\n",
    " print('1/4 Start download')\n",
    " !curl https://msmarco.blob.core.windows.net/msmarcoranking/collection.tar.gz -o data/msmarco_passage/collection.tar.gz --create-dirs\n",
    "\n",
    " # Unzip\n",
    " print('2/4 Unzip')\n",
    " !tar xvfz data/msmarco_passage/collection.tar.gz -C data/msmarco_passage\n",
    "\n",
    " # Map .tsv to .json\n",
    " print('3/4 Map tsv to json')\n",
    " !git clone https://github.com/castorini/anserini.git\n",
    " !cd anserini && git checkout ad5ba1c76196436f8a0e28efdb69960d4873efe3\n",
    " !cd anserini && python ./src/main/python/msmarco/convert_collection_to_jsonl.py \\\n",
    " --collection_path ../data/msmarco_passage/collection.tsv --output_folder ../data/msmarco_passage/collection_jsonl\n",
    "\n",
    " # Clean up\n",
    " print('4/4 Clean up')\n",
    " !rm data/msmarco_passage/collection.tar.gz\n",
    " !rm data/msmarco_passage/*.tsv\n",
    " !rm -rf sample_data\n",
    " !rm -rf -v anserini"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ad-TkqPZ7Qeq",
    "outputId": "e482f905-997e-46f7-c31e-4a6b31529946",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Index documents in Lucene\n",
    "if not os.path.exists('indexes/'):\n",
    " !python -m pyserini.index.lucene -collection JsonCollection -generator DefaultLuceneDocumentGenerator -threads 9 \\\n",
    " -input data/msmarco_passage/collection_jsonl -index indexes/lucene-index-msmarco-passage -storePositions -storeDocvectors -storeRaw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we fetch our queries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Data exploration\n",
    "We will start with some data exploration, to gain a better understanding of what we are dealing with and what pre-processing steps we should consider."
   ],
   "metadata": {
    "id": "1anAf-i975Jj",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we create an index reader and look at some of the Lucene index statistics."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "index_reader = IndexReader('indexes/lucene-index-msmarco-passage')"
   ],
   "metadata": {
    "id": "mxbZRdYN8OEG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Note that unless the index was built with `-optimize`, unique_terms will show -1\n",
    "lucene_stats = index_reader.stats()\n",
    "print(f'Number of documents in dataset:       {lucene_stats[\"documents\"]}')\n",
    "print(f'Number of empty documents in dataset: {lucene_stats[\"documents\"] - lucene_stats[\"non_empty_documents\"]}')\n",
    "print(f'Number of terms in dataset:           {lucene_stats[\"total_terms\"]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will sample some documents to:\n",
    "1. Look into the document length statistics and plot the number of words per document in a histogram\n",
    "2. Plot the most common words in a wordcloud\n",
    "3. Print some documents to look into"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Collect documents\n",
    "documents = pd.DataFrame(columns=['id', 'contents'])\n",
    "docs_filenames = glob.glob('data/msmarco_passage/collection_jsonl/*.json')\n",
    "\n",
    "for filename in docs_filenames:\n",
    " file_docs = pd.read_json(filename, lines=True)\n",
    " sample = file_docs.sample(1000, random_state=1)\n",
    " documents = pd.concat([documents, sample], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Document length statistics\n",
    "words = list(map(lambda x: wordpunct_tokenize(x), documents['contents']))\n",
    "lengths = np.array(list(map(lambda x: len(x), words)))\n",
    "\n",
    "print(f'Average document length: {lengths.mean()}')\n",
    "print(f'Minimum document length: {lengths.min()}')\n",
    "print(f'Maximum document length: {lengths.max()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Histogram\n",
    "plt.hist(lengths)\n",
    "plt.xlabel('Number of words in document')\n",
    "plt.ylabel('Number of documents')\n",
    "plt.title('Document lengths')\n",
    "plt.show()\n",
    "print('Figure 1. Histogram of the number of words per sampled document')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Wordcloud\n",
    "contents = ' '.join([word for word_list in words for word in word_list])\n",
    "\n",
    "wordcloud = WordCloud(width=1600,height=400).generate(contents)\n",
    "plt.figure(figsize = (25,25))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print('Figure 2. Wordcloud of most common words in documents sample')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print samples\n",
    "n_samples = 5\n",
    "for idx, document in enumerate(documents['contents'].iloc[:n_samples], 1):\n",
    " print(f'\\033[1m- Document {idx}:\\033[0m')\n",
    " print(document)\n",
    " print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Data pre-processing"
   ],
   "metadata": {
    "id": "2_rwYi9x6S0U",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "We have the texts\n",
    "We also have the Queries soon\n",
    "for BM25 and word2vec we will probably need stop word removal / stemming\n"
   ],
   "metadata": {
    "id": "8diXnq6d7QIj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Model implementation"
   ],
   "metadata": {
    "id": "ZrvHPWC-6U4G",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 Word2Vec"
   ],
   "metadata": {
    "id": "AGPQ_kGS6XfR",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "YTcik4Qm7Ohr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 ElMo"
   ],
   "metadata": {
    "id": "A1FiDcaO6aIj",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "mJjSiajC7GCM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3 BERT"
   ],
   "metadata": {
    "id": "E3ag1xNp6cHo",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ],
   "metadata": {
    "id": "MoyxHy9R7E3b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Model evaluation"
   ],
   "metadata": {
    "id": "J56a8-qZ6h7B",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gI7D25TI5tFL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "calculate previously handled metrics"
   ]
  }
 ]
}